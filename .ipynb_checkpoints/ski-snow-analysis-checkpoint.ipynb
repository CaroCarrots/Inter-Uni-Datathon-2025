{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "280302b8",
   "metadata": {},
   "source": [
    "# Inter-Uni Datathon 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff0dba5",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'ski_env (Python -1.-1.-1)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import os, sys, json, time, math, itertools, random, textwrap\n",
    "from datetime import datetime, timedelta, date\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (9, 5)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "\n",
    "# seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247f7406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Datathon 2026: Ultimate Ski Holiday Planner\n",
    "# **Goal:** Pick the optimal **week in 2026** and **ski resort** using visitation + climate data and public info on prices & features.\n",
    "#\n",
    "# **Key criteria:** visitors (crowding), snow/weather, prices, resort features.\n",
    "#\n",
    "# **Deliverables:**\n",
    "# - Clear recommendation (resort + week in 2026)\n",
    "# - Engaging visuals\n",
    "# - Transparent assumptions, trade-offs, and sensitivity checks\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 0. Setup & Configuration\n",
    "\n",
    "# %%\n",
    "# Environment checks & imports\n",
    "import os, sys, json, time, math, itertools, random, textwrap\n",
    "from datetime import datetime, timedelta, date\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (9, 5)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "\n",
    "# optional (comment-in if needed)\n",
    "# !pip3 -q install geopandas shapely pyproj meteostat prophet plotly\n",
    "\n",
    "# seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Project Parameters\n",
    "\n",
    "# %%\n",
    "PROJECT_ROOT = Path(\".\").resolve()\n",
    "DATA_DIR     = PROJECT_ROOT / \"data\"          # place raw data here\n",
    "INT_DIR      = PROJECT_ROOT / \"intermediate\"  # cleaned/intermediate data\n",
    "OUT_DIR      = PROJECT_ROOT / \"outputs\"       # figures & tables\n",
    "for d in [DATA_DIR, INT_DIR, OUT_DIR]:\n",
    "    d.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "CONFIG = {\n",
    "    \"year_target\": 2026,\n",
    "    \"analysis_week_start_day\": \"Monday\",  # weeks aligned to this weekday\n",
    "    \"min_base_depth_cm\": 50,              # example snow constraint\n",
    "    \"temp_comfort_range_C\": (-12, 2),     # perceived comfy ski temps\n",
    "    \"wind_max_ms\": 12,                    # wind comfort threshold\n",
    "    \"holiday_blackouts\": [                # e.g., periods to avoid or flag\n",
    "        {\"name\":\"Xmas/NY\", \"start\":\"2025-12-20\", \"end\":\"2026-01-05\"},\n",
    "        {\"name\":\"School hols\", \"start\":\"2026-06-20\", \"end\":\"2026-07-20\"},\n",
    "    ],\n",
    "    \"multi_objective_weights\": {          # tune for trade-offs\n",
    "        \"snow\": 0.35,\n",
    "        \"weather\": 0.20,\n",
    "        \"price\": 0.25,\n",
    "        \"crowding\": 0.20\n",
    "    }\n",
    "}\n",
    "CONFIG\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Data Inventory & Loading\n",
    "# Place provided **visitation** and **climate** datasets in `data/`.\n",
    "# Add any public data (price calendars, lift tickets, accommodation, resort features).\n",
    "\n",
    "# %%\n",
    "# --- expected file names (edit to your actual files) ---\n",
    "FILES = {\n",
    "    \"visitation\": DATA_DIR / \"visitation.csv\",       # e.g. daily/weekly counts by resort\n",
    "    \"climate\":    DATA_DIR / \"climate_daily.csv\",    # e.g. daily snowfall/temp/wind etc\n",
    "    \"resorts\":    DATA_DIR / \"resorts_meta.csv\",     # resort name, region, elevation, lifts, runs\n",
    "    \"prices\":     DATA_DIR / \"price_calendar.csv\",   # nightly hotel / lift ticket estimates by date/resort\n",
    "}\n",
    "\n",
    "# Load with dtype safety\n",
    "def load_csv(path):\n",
    "    if not path.exists():\n",
    "        print(f\"[WARN] Missing file: {path}\")\n",
    "        return pd.DataFrame()\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "visitation_raw = load_csv(FILES[\"visitation\"])\n",
    "climate_raw    = load_csv(FILES[\"climate\"])\n",
    "resorts_meta   = load_csv(FILES[\"resorts\"])\n",
    "prices_raw     = load_csv(FILES[\"prices\"])\n",
    "\n",
    "visitation_raw.head(), climate_raw.head(), resorts_meta.head(), prices_raw.head()\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 2.1 Quick Schema Checks\n",
    "\n",
    "# %%\n",
    "def summarize_df(df, name):\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    if df.empty:\n",
    "        print(\"EMPTY\")\n",
    "        return\n",
    "    display(df.head(3))\n",
    "    print(df.info())\n",
    "\n",
    "summarize_df(visitation_raw, \"visitation_raw\")\n",
    "summarize_df(climate_raw, \"climate_raw\")\n",
    "summarize_df(resorts_meta, \"resorts_meta\")\n",
    "summarize_df(prices_raw, \"prices_raw\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Cleaning & Harmonization\n",
    "# - Standardize date formats\n",
    "# - Ensure a consistent **resort_id** key across tables\n",
    "# - Handle missing values & outliers\n",
    "\n",
    "# %%\n",
    "# ---- Example cleaning (edit to your column names) ----\n",
    "def to_date(s):\n",
    "    return pd.to_datetime(s, errors=\"coerce\")\n",
    "\n",
    "# visitation\n",
    "if not visitation_raw.empty:\n",
    "    visitation = visitation_raw.copy()\n",
    "    # expected: [date, resort_id, visitors]\n",
    "    visitation[\"date\"] = to_date(visitation[\"date\"])\n",
    "else:\n",
    "    visitation = pd.DataFrame()\n",
    "\n",
    "# climate\n",
    "if not climate_raw.empty:\n",
    "    climate = climate_raw.copy()\n",
    "    # expected: [date, resort_id, snowfall_cm, base_depth_cm, temp_C, wind_ms, precip_mm]\n",
    "    climate[\"date\"] = to_date(climate[\"date\"])\n",
    "else:\n",
    "    climate = pd.DataFrame()\n",
    "\n",
    "# prices\n",
    "if not prices_raw.empty:\n",
    "    prices = prices_raw.copy()\n",
    "    # expected: [date, resort_id, lift_price_usd, hotel_price_usd]\n",
    "    prices[\"date\"] = to_date(prices[\"date\"])\n",
    "else:\n",
    "    prices = pd.DataFrame()\n",
    "\n",
    "# resorts meta\n",
    "if not resorts_meta.empty:\n",
    "    resorts = resorts_meta.copy()\n",
    "    # expected: [resort_id, name, country, lat, lon, elevation_m, runs, lifts, snowmaking_%]\n",
    "else:\n",
    "    resorts = pd.DataFrame()\n",
    "\n",
    "# basic NA handling (customize per field criticality)\n",
    "for df in [visitation, climate, prices]:\n",
    "    if not df.empty:\n",
    "        df.dropna(subset=[\"date\",\"resort_id\"], inplace=True)\n",
    "\n",
    "# persist cleaned\n",
    "visitation.to_csv(INT_DIR/\"visitation_clean.csv\", index=False)\n",
    "climate.to_csv(INT_DIR/\"climate_clean.csv\", index=False)\n",
    "prices.to_csv(INT_DIR/\"prices_clean.csv\", index=False)\n",
    "resorts.to_csv(INT_DIR/\"resorts_clean.csv\", index=False)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "# %%\n",
    "# 4.1 Coverage by resort\n",
    "if not visitation.empty and not climate.empty:\n",
    "    coverage = (visitation.groupby(\"resort_id\")[\"date\"].nunique()\n",
    "                .to_frame(\"visitation_days\")\n",
    "                .join(climate.groupby(\"resort_id\")[\"date\"].nunique()\n",
    "                      .to_frame(\"climate_days\"), how=\"outer\"))\n",
    "    coverage.sort_values(\"visitation_days\", ascending=False).head(10)\n",
    "\n",
    "# %%\n",
    "# 4.2 Seasonal visitation pattern (example resort)\n",
    "example_resort = visitation[\"resort_id\"].iloc[0] if not visitation.empty else None\n",
    "if example_resort:\n",
    "    df = visitation[visitation[\"resort_id\"] == example_resort].copy()\n",
    "    df = df.sort_values(\"date\")\n",
    "    plt.figure()\n",
    "    plt.plot(df[\"date\"], df[\"visitors\"], label=f\"resort {example_resort}\")\n",
    "    plt.title(\"Visitation over time\")\n",
    "    plt.xlabel(\"date\"); plt.ylabel(\"visitors\"); plt.legend(); plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# %%\n",
    "# 4.3 Snow & temperature distribution (all resorts)\n",
    "if not climate.empty:\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12,4))\n",
    "    climate[\"snowfall_cm\"].dropna().plot(kind=\"hist\", bins=40, ax=axs[0])\n",
    "    axs[0].set_title(\"Daily Snowfall (cm)\")\n",
    "    climate[\"temp_C\"].dropna().plot(kind=\"hist\", bins=40, ax=axs[1])\n",
    "    axs[1].set_title(\"Daily Temperature (°C)\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Feature Engineering\n",
    "# - Aggregate to **weekly** metrics for 2026 alignment\n",
    "# - Snow comfort score, weather comfort score\n",
    "# - Price per skier-day\n",
    "# - Crowding index (from visitation)\n",
    "\n",
    "# %%\n",
    "def to_week_start(d, week_start=\"Monday\"):\n",
    "    # normalize date to week-start (ISO week assumed)\n",
    "    offset = {\"Monday\":0,\"Sunday\":6}.get(week_start, 0)\n",
    "    return (d - pd.to_timedelta((d.weekday()-offset)%7, unit=\"D\")).normalize()\n",
    "\n",
    "def weekly_agg(df, value_cols, ops):\n",
    "    tmp = df.copy()\n",
    "    tmp[\"week_start\"] = tmp[\"date\"].apply(lambda x: to_week_start(x, CONFIG[\"analysis_week_start_day\"]))\n",
    "    grouped = tmp.groupby([\"resort_id\",\"week_start\"])[value_cols].agg(ops)\n",
    "    grouped.columns = [\"_\".join(col).strip() if isinstance(col, tuple) else col for col in grouped.columns.values]\n",
    "    return grouped.reset_index()\n",
    "\n",
    "# visitation weekly\n",
    "vis_week = weekly_agg(visitation, [\"visitors\"], {\"visitors\":\"sum\"}) if not visitation.empty else pd.DataFrame()\n",
    "\n",
    "# climate weekly (custom: sums/means)\n",
    "if not climate.empty:\n",
    "    clim_week = weekly_agg(\n",
    "        climate,\n",
    "        [\"snowfall_cm\",\"base_depth_cm\",\"temp_C\",\"wind_ms\",\"precip_mm\"],\n",
    "        {\"snowfall_cm\":\"sum\",\"base_depth_cm\":\"mean\",\"temp_C\":\"mean\",\"wind_ms\":\"mean\",\"precip_mm\":\"sum\"}\n",
    "    )\n",
    "else:\n",
    "    clim_week = pd.DataFrame()\n",
    "\n",
    "# price weekly\n",
    "if not prices.empty:\n",
    "    price_week = weekly_agg(\n",
    "        prices, [\"lift_price_usd\",\"hotel_price_usd\"],\n",
    "        {\"lift_price_usd\":\"mean\",\"hotel_price_usd\":\"mean\"}\n",
    "    )\n",
    "else:\n",
    "    price_week = pd.DataFrame()\n",
    "\n",
    "# merge all\n",
    "dfs = [vis_week, clim_week, price_week]\n",
    "weekly = None\n",
    "for i, d in enumerate(dfs):\n",
    "    if d is None or d.empty: continue\n",
    "    weekly = d if weekly is None else weekly.merge(d, on=[\"resort_id\",\"week_start\"], how=\"outer\")\n",
    "\n",
    "weekly = weekly.merge(resorts, on=\"resort_id\", how=\"left\") if (weekly is not None and not resorts.empty) else weekly\n",
    "weekly.head()\n",
    "\n",
    "# %%\n",
    "# Derived scores\n",
    "def clamp(v, lo, hi): return max(lo, min(hi, v))\n",
    "\n",
    "def snow_score(row):\n",
    "    # example: base depth importance then snowfall bonus\n",
    "    depth = row.get(\"base_depth_cm_mean\", np.nan)\n",
    "    snow  = row.get(\"snowfall_cm_sum\", np.nan)\n",
    "    s = 0\n",
    "    if pd.notna(depth):\n",
    "        s += np.interp(clamp(depth, 0, 200), [0, CONFIG[\"min_base_depth_cm\"], 200], [0, 0.7, 1.0])\n",
    "    if pd.notna(snow):\n",
    "        s += np.interp(clamp(snow, 0, 70), [0, 10, 40, 70], [0, 0.2, 0.3, 0.35])\n",
    "    return clamp(s, 0, 1)\n",
    "\n",
    "def weather_score(row):\n",
    "    t = row.get(\"temp_C_mean\", np.nan)\n",
    "    w = row.get(\"wind_ms_mean\", np.nan)\n",
    "    s = 0\n",
    "    if pd.notna(t):\n",
    "        lo, hi = CONFIG[\"temp_comfort_range_C\"]\n",
    "        # bell-ish preference\n",
    "        s += 1 - min(abs((t - (lo+hi)/2) / (hi-lo)), 1)\n",
    "    if pd.notna(w):\n",
    "        s += 1 - min(w / CONFIG[\"wind_max_ms\"], 1)\n",
    "    return clamp(s/2, 0, 1)\n",
    "\n",
    "def price_score(row):\n",
    "    # lower is better; normalize inverse\n",
    "    lp = row.get(\"lift_price_usd_mean\", np.nan)\n",
    "    hp = row.get(\"hotel_price_usd_mean\", np.nan)\n",
    "    vals = [v for v in [lp, hp] if pd.notna(v)]\n",
    "    if not vals: return np.nan\n",
    "    s = 1 - min(np.mean(vals) / (np.nanpercentile(vals, 90) if len(vals)>5 else (max(vals)+1e-9)), 1)\n",
    "    return clamp(s, 0, 1)\n",
    "\n",
    "def crowding_score(row):\n",
    "    # fewer visitors better; inverse of visitors\n",
    "    v = row.get(\"visitors_sum\", np.nan)\n",
    "    if pd.isna(v): return np.nan\n",
    "    # scale relative to distribution\n",
    "    return clamp(1 - (v / (np.nanpercentile(weekly[\"visitors_sum\"], 90) if \"visitors_sum\" in weekly and weekly[\"visitors_sum\"].notna().any() else (v+1e-9))), 0, 1)\n",
    "\n",
    "if weekly is not None:\n",
    "    weekly[\"score_snow\"]     = weekly.apply(snow_score, axis=1)\n",
    "    weekly[\"score_weather\"]  = weekly.apply(weather_score, axis=1)\n",
    "    weekly[\"score_price\"]    = weekly.apply(price_score, axis=1)\n",
    "    weekly[\"score_crowding\"] = weekly.apply(crowding_score, axis=1)\n",
    "\n",
    "weekly.head()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Forecasting 2026 (Optional)\n",
    "# If provided data stop at 2025, build simple forecasts for:\n",
    "# - **Visitation** (ARIMA/Prophet or seasonal naive)\n",
    "# - **Snow/weather** (climatology or external climate normals)\n",
    "# Keep it simple unless you have time.\n",
    "\n",
    "# %%\n",
    "# Example: seasonal-naive visitation forecast placeholder\n",
    "def seasonal_naive_weekly(df, year_target=2026):\n",
    "    if df.empty: return df\n",
    "    base = df.copy()\n",
    "    base[\"year\"] = base[\"week_start\"].dt.year\n",
    "    hist = base[base[\"year\"] < year_target]\n",
    "    if hist.empty: return df\n",
    "    # map week-of-year medians\n",
    "    base[\"woy\"] = base[\"week_start\"].dt.isocalendar().week.astype(int)\n",
    "    med = hist.groupby([\"resort_id\",\"woy\"])[\"visitors_sum\"].median().rename(\"visitors_fcst\")\n",
    "    # target weeks\n",
    "    weeks_2026 = pd.date_range(f\"{year_target}-01-01\", f\"{year_target}-12-31\", freq=\"W-\" + CONFIG[\"analysis_week_start_day\"][0:3].upper())\n",
    "    grid = pd.MultiIndex.from_product([base[\"resort_id\"].dropna().unique(), weeks_2026], names=[\"resort_id\",\"week_start\"]).to_frame(index=False)\n",
    "    grid[\"woy\"] = grid[\"week_start\"].dt.isocalendar().week.astype(int)\n",
    "    out = grid.merge(med, on=[\"resort_id\",\"woy\"], how=\"left\")\n",
    "    return out\n",
    "\n",
    "visitation_fcst = seasonal_naive_weekly(vis_week) if not vis_week.empty else pd.DataFrame()\n",
    "visitation_fcst.head()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. Multi-Objective Scoring (Resort × Week 2026)\n",
    "# Combine normalized scores with weights to produce a final score.\n",
    "\n",
    "# %%\n",
    "def combine_scores(row, w=CONFIG[\"multi_objective_weights\"]):\n",
    "    parts = []\n",
    "    for k_src, k_w in [(\"score_snow\",\"snow\"),(\"score_weather\",\"weather\"),(\"score_price\",\"price\"),(\"score_crowding\",\"crowding\")]:\n",
    "        v = row.get(k_src, np.nan)\n",
    "        if pd.notna(v): parts.append((w[k_w]*v, w[k_w]))\n",
    "    if not parts: return np.nan\n",
    "    num = sum(p[0] for p in parts)\n",
    "    den = sum(p[1] for p in parts)\n",
    "    return num/den if den else np.nan\n",
    "\n",
    "scores_2026 = weekly.copy() if weekly is not None else pd.DataFrame()\n",
    "if scores_2026 is not None and not scores_2026.empty:\n",
    "    scores_2026 = scores_2026[scores_2026[\"week_start\"].dt.year == CONFIG[\"year_target\"]].copy()\n",
    "    scores_2026[\"score_final\"] = scores_2026.apply(combine_scores, axis=1)\n",
    "\n",
    "top10 = (scores_2026.sort_values(\"score_final\", ascending=False)\n",
    "         .head(10)\n",
    "         .merge(resorts[[\"resort_id\",\"name\",\"country\"]], on=\"resort_id\", how=\"left\") if scores_2026 is not None else pd.DataFrame())\n",
    "top10\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8. Visualization: Storytelling Dash\n",
    "# - Rank plot: best weeks overall\n",
    "# - Resort drill-down: snow/price/crowding trade-offs\n",
    "# - Sensitivity: change weights and observe ranking shifts\n",
    "\n",
    "# %%\n",
    "# 8.1 Top weeks (bar)\n",
    "if scores_2026 is not None and not scores_2026.empty:\n",
    "    disp = (scores_2026.sort_values(\"score_final\", ascending=False)\n",
    "            .head(12)\n",
    "            .merge(resorts[[\"resort_id\",\"name\"]], on=\"resort_id\", how=\"left\"))\n",
    "    plt.figure()\n",
    "    plt.barh(disp[\"name\"] + \" | \" + disp[\"week_start\"].dt.strftime(\"%Y-%m-%d\"), disp[\"score_final\"])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(\"Top Resort × Week Combinations (Score)\")\n",
    "    plt.xlabel(\"final score (0–1)\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# %%\n",
    "# 8.2 Trade-off scatter (price vs snow), sized by visitors, colored by final score\n",
    "if scores_2026 is not None and not scores_2026.empty:\n",
    "    df = scores_2026.copy()\n",
    "    x = df[\"hotel_price_usd_mean\"]\n",
    "    y = df[\"base_depth_cm_mean\"]\n",
    "    s = (df[\"visitors_sum\"].fillna(df[\"visitors_sum\"].median()) if \"visitors_sum\" in df else pd.Series(50, index=df.index))\n",
    "    c = df[\"score_final\"]\n",
    "    plt.figure()\n",
    "    sc = plt.scatter(x, y, s=20 + 80*(s/s.max()), c=c, alpha=0.7)\n",
    "    plt.colorbar(sc, label=\"final score\")\n",
    "    plt.xlabel(\"Avg hotel price (USD, weekly)\")\n",
    "    plt.ylabel(\"Avg base depth (cm, weekly)\")\n",
    "    plt.title(\"Trade-offs: Price vs Snow (size ~ visitors)\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9. Sensitivity Analysis\n",
    "# Test how rankings change if weights vary (e.g., budget-focused vs powder-chaser profiles).\n",
    "\n",
    "# %%\n",
    "def recompute_with_weights(weights):\n",
    "    tmp = scores_2026.copy()\n",
    "    tmp[\"score_final\"] = tmp.apply(lambda r: combine_scores(r, weights), axis=1)\n",
    "    best = tmp.sort_values(\"score_final\", ascending=False).head(5)\n",
    "    return best.merge(resorts[[\"resort_id\",\"name\"]], on=\"resort_id\", how=\"left\")[[\"name\",\"week_start\",\"score_final\"]]\n",
    "\n",
    "profiles = {\n",
    "    \"Balanced\": CONFIG[\"multi_objective_weights\"],\n",
    "    \"Budget\":   {\"snow\":0.25, \"weather\":0.15, \"price\":0.45, \"crowding\":0.15},\n",
    "    \"Powder\":   {\"snow\":0.55, \"weather\":0.20, \"price\":0.10, \"crowding\":0.15},\n",
    "    \"Crowd-averse\":{\"snow\":0.30, \"weather\":0.20, \"price\":0.15, \"crowding\":0.35},\n",
    "}\n",
    "\n",
    "sens_table = {}\n",
    "if scores_2026 is not None and not scores_2026.empty:\n",
    "    for k, w in profiles.items():\n",
    "        sens_table[k] = recompute_with_weights(w)\n",
    "\n",
    "for k, df in sens_table.items():\n",
    "    print(f\"\\n== Profile: {k} ==\")\n",
    "    display(df)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10. Constraints & Feasibility Checks\n",
    "# - Flag blackout periods (holidays)\n",
    "# - Ensure weather not hazardous (extreme wind/temps)\n",
    "# - Availability (if you integrate scraping or availability feeds)\n",
    "\n",
    "# %%\n",
    "def flag_blackouts(df):\n",
    "    out = df.copy()\n",
    "    out[\"blackout\"] = False\n",
    "    for b in CONFIG[\"holiday_blackouts\"]:\n",
    "        start = pd.to_datetime(b[\"start\"])\n",
    "        end   = pd.to_datetime(b[\"end\"])\n",
    "        out.loc[(out[\"week_start\"]>=start)&(out[\"week_start\"]<=end), \"blackout\"] = True\n",
    "    return out\n",
    "\n",
    "if scores_2026 is not None and not scores_2026.empty:\n",
    "    scores_2026 = flag_blackouts(scores_2026)\n",
    "    # Example filter (optional): exclude blackout weeks from final short-list\n",
    "    shortlist = scores_2026[(scores_2026[\"blackout\"] == False)].copy()\n",
    "    shortlist = shortlist.sort_values(\"score_final\", ascending=False).head(10)\n",
    "    shortlist.merge(resorts[[\"resort_id\",\"name\",\"country\"]], on=\"resort_id\", how=\"left\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 11. Final Recommendation\n",
    "# Compose the narrative: why this week & resort stand out, with visuals that back the claims.\n",
    "\n",
    "# %%\n",
    "def pick_final(df):\n",
    "    if df.empty:\n",
    "        return None\n",
    "    best = df.sort_values(\"score_final\", ascending=False).iloc[0]\n",
    "    return best\n",
    "\n",
    "choice = pick_final(shortlist if 'shortlist' in globals() else scores_2026)\n",
    "if choice is not None:\n",
    "    rid = choice[\"resort_id\"]\n",
    "    rname = resorts.loc[resorts[\"resort_id\"]==rid,\"name\"].values[0] if not resorts.empty else f\"Resort {rid}\"\n",
    "    print(\"=== Recommended Trip ===\")\n",
    "    print(f\"Resort: {rname} (ID: {rid})\")\n",
    "    print(f\"Week starting: {choice['week_start'].date()}\")\n",
    "    print(f\"Final score: {choice['score_final']:.3f}\")\n",
    "    print(\"\\n--- key metrics ---\")\n",
    "    keys = [k for k in choice.index if (\"score_\" in k) or k.endswith((\"_mean\",\"_sum\"))]\n",
    "    display(choice[keys])\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 12. Figure Export & Report Artifacts\n",
    "\n",
    "# %%\n",
    "# save key tables\n",
    "if 'shortlist' in globals() and not shortlist.empty:\n",
    "    shortlist_out = shortlist.merge(resorts[[\"resort_id\",\"name\",\"country\"]], on=\"resort_id\", how=\"left\")\n",
    "    shortlist_out.to_csv(OUT_DIR/\"shortlist.csv\", index=False)\n",
    "\n",
    "# example: export a simple PNG chart\n",
    "if scores_2026 is not None and not scores_2026.empty:\n",
    "    disp = (scores_2026.sort_values(\"score_final\", ascending=False)\n",
    "            .head(8)\n",
    "            .merge(resorts[[\"resort_id\",\"name\"]], on=\"resort_id\", how=\"left\"))\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.bar(disp[\"name\"] + \"\\n\" + disp[\"week_start\"].dt.strftime(\"%Y-%m-%d\"), disp[\"score_final\"])\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"final score\")\n",
    "    plt.title(\"Top Picks\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR/\"top_picks.png\", dpi=180)\n",
    "    plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 13. Appendix\n",
    "# - **Data sources** & license notes\n",
    "# - **Assumptions:** how scores were constructed\n",
    "# - **Limitations:** forecast uncertainty, data sparsity\n",
    "# - **Next steps:** scrape live prices/availability, add lift wait times, avalanche risk indices, etc.\n",
    "\n",
    "# %%\n",
    "APPENDIX = {\n",
    "    \"data_sources\": [\n",
    "        \"Provided visitation dataset\",\n",
    "        \"Provided climate dataset\",\n",
    "        \"Public price calendars (e.g., resort sites / OTAs) — if used\",\n",
    "        \"Resort meta info (elevation, lifts, runs) — if used\"\n",
    "    ],\n",
    "    \"assumptions\": [\n",
    "        \"Weekly aggregation aligns with trip planning\",\n",
    "        f\"Weights used: {CONFIG['multi_objective_weights']}\",\n",
    "        \"Comfort ranges reflect typical skier preferences\"\n",
    "    ],\n",
    "    \"limitations\": [\n",
    "        \"Climatology ≠ weather guarantee\",\n",
    "        \"Visitation may vary due to events/holidays\",\n",
    "        \"Price estimates may not include promotions/fees\"\n",
    "    ]\n",
    "}\n",
    "print(json.dumps(APPENDIX, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ski_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "-1.-1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
